import numpy as np
import pandas as pd
from scipy.special import erfc
from scipy.integrate import quad, solve_ivp
import matplotlib.pyplot as plt
from genetic_algorithm import GeneticAlgorithm


## BaFe12O19
df = pd.DataFrame({
    "B_kG": [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3.5, 3, 2.5, 2, 1.5, 1, 0.5, 0, -0.5, -1, -1.5, -2, -2.5, -3, -3.5, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14],  # Add your H field data
    "M": [21.35, 22.45, 23.93, 25.5, 27.16, 28.75, 30.28, 32.03, 33.44, 39.83, 47.08, 50.88, 53.81, 55.9, 57.64, 59.25, 60.81, 62.2, 63.62, 62.73, 61.41, 60.09, 58.48, 56.92, 55.14, 53.24, 51.32, 49.24, 47.18, 45.92, 44.52, 43.24, 41.91, 40.44, 38.95, 37.46, 35.61, 33.54, 31.13, 28.48, 25.68, 22.38, 17.88, 9.6, -2.27, -27.65, -42.5, -50.29, -53.76, -56.14, -58.03, -59.65, -61.15, -62.55, -63.85]
    })


bounds = np.array([
    [5, 7],    # mu
    [0.1, 2],    # sigma
    [2, 3.0],    # omega
    [1e-3, 2],   # tau
    [100, 400.0],  # Rc
    [0.01, 6],   # H0
    [20.0, 200.0]   # Ms
])


# ## SrFe12O19
# df = pd.DataFrame({
#     "B_kG": [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3.5, 3, 2.5, 2, 1.5, 1, 0.5, 0, -0.5, -1, -1.5, -2, -2.5, -3, -3.5, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14],  # Add your H field data
#     "M": [0.37, 0.86, 1.61, 2.41, 3.29, 4.19, 4.9, 5.81, 6.61, 8.61, 13.7, 19.01, 22.06, 23.42, 24.29, 25.01, 25.65, 26.24, 26.76, 26.37, 25.87, 25.33, 24.73, 24.1, 23.38, 22.6, 21.84, 21.01, 20.13, 19.62, 19.02, 18.47, 17.9, 17.29, 16.66, 15.99, 15.2, 14.37, 13.2, 12.17, 11.18, 10.22, 9.26, 7.95, 6.99, 3.81, -6.84, -18.26, -21.79, -23.42, -24.34, -25.07, -25.71, -26.34, -26.82]
#     })

# bounds = np.array([
#     [3, 4],    # mu
#     [0.1, 2],    # sigma
#     [2.1, 3.0],    # omega
#     [1e-3, 2],   # tau
#     [50, 300.0],  # Rc
#     [0.01, 6],   # H0
#     [20.0, 200.0]   # Ms
# ])



# ## MnFe2O4
# df = pd.DataFrame({
#     "B_kG": [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6, 2.8, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0, 9.5, 9.0, 8.5, 8.0, 7.5, 7.0, 6.5, 6.0, 5.5, 5.0, 4.5, 4.0, 3.5, 3.0, 2.8, 2.6, 2.4, 2.2, 2.0, 1.8, 1.6, 1.4, 1.2, 1.0, 0.8, 0.6, 0.4, 0.2, 0.19, 0.18, 0.17, 0.16, 0.15, 0.14, 0.13, 0.12, 0.11, 0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01, 0, -0.01, -0.02, -0.03, -0.04, -0.05, -0.06, -0.07, -0.08, -0.09, -0.1, -0.11, -0.12, -0.13, -0.14, -0.15, -0.16, -0.17, -0.18, -0.19, -0.4, -0.6, -0.8, -1.0, -1.2, -1.4, -1.6, -1.8, -2.0, -2.2, -2.4, -2.6, -2.8, -3.0, -3.5, -4.0, -4.5, -5.0, -5.5, -6.0, -6.5, -7.0, -7.5, -8.0, -8.5, -9.0, -9.5, -10.0, -9.5, -9.0, -8.5, -8.0, -7.5, -7.0, -6.5, -6.0, -5.5, -5.0, -4.5, -4.0, -3.5, -3.0, -2.8, -2.6, -2.4, -2.2, -2.0, -1.8, -1.6, -1.4, -1.2, -1.0, -0.8, -0.6, -0.4, -0.2, -0.19, -0.18, -0.17, -0.16, -0.15, -0.14, -0.13, -0.12, -0.11, -0.1, -0.09, -0.08, -0.07, -0.06, -0.05, -0.04, -0.03, -0.02, -0.01, 0],
#     "M": [-4.46272, -3.90998, -3.2515, -2.60083, -1.91642, -1.19465, -0.4624, 0.2763, 1.00188, 1.76716, 2.51173, 3.22179, 3.93792, 4.63524, 5.33819, 5.99184, 6.6255, 7.2445, 7.82926, 8.43545, 8.94855, 15.98557, 19.55303, 21.62132, 23.03169, 24.03495, 24.78794, 25.38299, 25.8691, 26.3112, 26.63955, 26.94363, 27.23327, 27.47711, 27.69461, 28.165, 28.55612, 28.88443, 29.21143, 29.43739, 29.68222, 29.88701, 30.07646, 30.24692, 30.39768, 30.58757, 30.69383, 30.82202, 30.9502, 30.83466, 30.70158, 30.56153, 30.41425, 30.25005, 30.08177, 29.89267, 29.73012, 29.47074, 29.21662, 28.93319, 28.61818, 28.23513, 27.76961, 27.54888, 27.30592, 27.03839, 26.73803, 26.39091, 26.02943, 25.52581, 24.95447, 24.23735, 23.30688, 22.04924, 20.26763, 17.65761, 13.29644, 12.95508, 12.62192, 12.31175, 11.98988, 11.65259, 11.32877, 10.9445, 10.56951, 10.17983, 9.76661, 9.3482, 8.9006, 8.45784, 7.96179, 7.46588, 6.93765, 6.3398, 5.72112, 5.10245, 4.46272, 3.80718, 3.2412, 2.53282, 1.87617, 1.12455, 0.38408, -0.32883, -1.11165, -1.84756, -2.56219, -3.32836, -4.02002, -4.74623, -5.40667, -6.10466, -6.73709, -7.3319, -7.90611, -8.53299, -16.16666, -19.70552, -21.77981, -23.16889, -24.15645, -24.90714, -25.49624, -25.97858, -26.38415, -26.73492, -27.04254, -27.30995, -27.59359, -27.77671, -28.24756, -28.63612, -28.96552, -29.2502, -29.50448, -29.72676, -29.93327, -30.11835, -30.28855, -30.45933, -30.60972, -30.74684, -30.87248, -30.99813, -30.86852, -30.72852, -30.58745, -30.43283, -30.26704, -30.09469, -29.90665, -29.69547, -29.46802, -29.2136, -28.92568, -28.5919, -28.20058, -27.72989, -27.50665, -27.26465, -26.99691, -26.69237, -26.34507, -25.94502, -25.46678, -24.88493, -24.16484, -23.23532, -21.98073, -20.19526, -17.54121, -13.20076, -12.83974, -12.52653, -12.20035, -11.88056, -11.52732, -11.18245, -10.83946, -10.42777, -10.03113, -9.63998, -9.22497, -8.77614, -8.31426, -7.82279, -7.28233, -6.76369, -6.21464, -5.60291, -4.99699, -4.46272]
#     })

# bounds = np.array([
#     [1, 4],    # mu
#     [0.1, 2],    # sigma
#     [2, 3.0],    # omega
#     [1e-3, 1],   # tau
#     [10, 30.0],  # Rc
#     [0.01, 1],   # H0
#     [20.0, 80.0]   # Ms
# ])




# ## NiZnFe2O4
# df = pd.DataFrame({
#     "B_kG": [0.0,0.025,0.05,0.075,0.1,0.125,0.15,0.175,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,2.2,2.4,2.6,2.8,3.0,3.5,4.0,4.5,5.0,5.5,6.0,6.5,7.0,7.5,8.0,8.5,9.0,9.5,10.0,9.5,9.0,8.5,8.0,7.5,7.0,6.5,6.0,5.5,5.0,4.5,4.0,3.5,3.0,2.8,2.6,2.4,2.2,2.0,1.8,1.6,1.4,1.2,1.0,0.8,0.6,0.4,0.2,0.175,0.15,0.125,0.1,0.075,0.05,0.025,0.0,-0.025,-0.05,-0.075,-0.1,-0.125,-0.15,-0.4,-0.6,-0.8,-1.0,-1.2,-1.4,-1.6,-1.8,-2.0,-2.2,-2.4,-2.6,-2.8,-3.0,-3.5,-4.0,-4.5,-5.0,-5.5,-6.0,-6.5,-7.0,-7.5,-8.0,-8.5,-9.0,-9.5,-10.0,-9.5,-9.0,-8.5,-8.0,-7.5,-7.0,-6.5,-6.0,-5.5,-5.0,-4.5,-4.0,-3.5,-3.0,-2.8,-2.6,-2.4,-2.2,-2.0,-1.8,-1.6,-1.4,-1.2,-1.0,-0.8,-0.6,-0.4,-0.2,-0.175,-0.15,-0.125,-0.1,-0.075,-0.05,-0.025,0.0],  # Add your H field data
#     "M": [-0.08472,3.83194,7.08586,10.13037,11.54301,12.95564,14.36828,15.78091,17.31844,22.06296,24.4692,25.88395,26.84165,27.54441,28.04759,28.4582,28.79784,29.11985,29.35853,29.57732,29.78233,30.00516,30.14257,30.50898,30.8536,31.11251,31.35271,31.57515,31.80937,31.97888,32.15343,32.31242,32.46332,32.63746,32.75598,32.87869,33.00141,32.87323,32.76798,32.60516,32.47947,32.32215,32.19551,31.9892,31.81611,31.60764,31.38279,31.1358,30.85929,30.59046,30.18015,30.02055,29.8306,29.62815,29.43264,29.14532,28.8522,28.52128,28.10787,27.58948,26.92078,26.01368,24.5825,22.47423,17.39987,16.41443,15.26869,13.9306,12.32188,10.37025,7.93576,4.82636,-0.70991,-3.94055,-6.90531,-8.47624,-10.04718,-11.61812,-13.18906,-22.22506,-24.59136,-26.02534,-26.97908,-27.65392,-28.17273,-28.62113,-28.93829,-29.22528,-29.47465,-29.71744,-29.91732,-30.09908,-30.26864,-30.63539,-30.94997,-31.25663,-31.4735,-31.69606,-31.9143,-32.10076,-32.27457,-32.4344,-32.58581,-32.71909,-32.8919,-32.9902,-33.0885,-32.99419,-32.86322,-32.72635,-32.58238,-32.43608,-32.27963,-32.13417,-31.91462,-31.72322,-31.50182,-31.25244,-30.97578,-30.6589,-30.28924,-30.1178,-29.9299,-29.72446,-29.53441,-29.25664,-28.97762,-28.63089,-28.21327,-27.69751,-27.02342,-26.08145,-24.66957,-22.53553,-17.409,-16.4131,-15.25401,-13.8861,-12.27676,-10.30569,-7.81728,-4.32543,-0.08472]       # Add your M data
# })

# Parameter Bounds
# bounds = np.array([
#     [0.0, 3.0],    # mu
#     [0.1, 2.0],    # sigma
#     [2.1, 3.0],    # omega
#     [1e-3, 1.0],   # tau
#     [10.0, 20.0],  # Rc
#     [0.01, 3.0],   # H0
#     [20.0, 80.0]   # Ms
# ])





# ## Fe/BaFe12O19
# df = pd.DataFrame({
#     "B_kG": [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3.5, 3, 2.5, 2, 1.5, 1, 0.5, 0, -0.5, -1, -1.5, -2, -2.5, -3, -3.5, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14],  # Add your H field data
#     "M": [37.9, 48.94, 60.42, 69.68, 76.74, 82.23, 86.38, 90, 92.34, 96.15, 101.61, 104.41, 107.29, 109.37, 110.66, 111.79, 112.78, 113.49, 114.23, 113.77, 113.33, 112.5, 111.73, 110.47, 109.65, 108.55, 107.4, 106.05, 103.67, 101.77, 99.11, 96.07, 91.89, 84.76, 77.39, 65.41, 44.03, 25.06, 1.06, -20, -40.66, -56.94, -71.34, -83.18, -89.83, -98.38, -103.76, -106.01, -107.96, -109.41, -110.54, -111.2, -112.02, -112.65, -112.92]
#     })

# bounds = np.array([
#     [4, 6],    # mu
#     [0.1, 2],    # sigma
#     [2.1, 3.0],    # omega
#     [1e-3, 2],   # tau
#     [200, 500.0],  # Rc
#     [0.01, 2],   # H0
#     [20.0, 200.0]   # Ms
# ])






H_empirical = df["B_kG"].values
B_empirical = df["M"].values
t_grid = np.linspace(0, 1, len(H_empirical))


def expectation(m,s,o):
    fval = (o/(o-1)) * np.exp(m+(s**2)/2)
    return fval

# MLP-related Functions
def mlp_pdf(r, mu, sigma, omega):
    coeff = (omega / 2) * r**(-omega - 1)
    exp_term = np.exp(omega * mu + 0.5 * (omega * sigma)**2)
    erfc_arg = (omega * sigma - (np.log(r) - mu) / sigma) / np.sqrt(2)
    return coeff * exp_term * erfc(erfc_arg)

def mlp_cdf(r, mu, sigma, omega):
    term1 = 0.5 * erfc(-(np.log(r) - mu) / (np.sqrt(2) * sigma))
    term2 = (1 / (2 * r**omega)) * np.exp(omega * mu + 0.5 * omega**2 * sigma**2)
    term2 *= erfc((omega * sigma - (np.log(r) - mu) / sigma) / np.sqrt(2))
    return term1 - term2

def mlp_coercivity_pdf_conditional(h, mu, sigma, omega, H0, Rc):
    h = np.clip(h, 1e-6, H0 - 1e-6)
    r = Rc * H0 / (H0 - h)
    dr_dh = Rc * H0 / (H0 - h)**2
    coeff = (omega / 2) * (1 / r)**(1 + omega)
    exp_term = np.exp(omega * mu + 0.5 * (omega * sigma)**2)
    erfc_arg = (omega * sigma - (np.log(r) - mu) / sigma) / np.sqrt(2)
    numerator = dr_dh * coeff * exp_term * erfc(erfc_arg)
    denominator = 1 - mlp_cdf(Rc, mu, sigma, omega)
    return numerator / denominator

def M_eq_func_conditional(H_array, mu, sigma, omega, Rc, H0, Ms):
    M_vals = []
    for H in H_array:
        integrand = lambda h: np.tanh(H / h) * mlp_coercivity_pdf_conditional(h, mu, sigma, omega, H0, Rc)
        M, _ = quad(integrand, 1e-3, H0 - 1e-3, limit=100)
        M_vals.append(Ms * M)
    return np.array(M_vals)

def dMdt_conditional(t, M, t_grid, M_eq, tau):
    return (np.interp(t, t_grid, M_eq) - M) / tau

def simulate_M_dynamic_conditional(H_vals, mu, sigma, omega, Rc, H0, Ms, tau, t_grid):
    M_eq = M_eq_func_conditional(H_vals, mu, sigma, omega, Rc, H0, Ms)
    sol = solve_ivp(
        lambda t, M: dMdt_conditional(t, M, t_grid, M_eq, tau),
        [t_grid[0], t_grid[-1]], [M_eq[0]], t_eval=t_grid,
        rtol=1e-6, atol=1e-9
    )
    return sol.y[0]

# Rejection Sampling and Conditional Expectation
def sample_mlp_truncated(mu, sigma, omega, Rc, n_samples=100000):
    r_vals = []
    max_pdf = mlp_pdf(Rc + 1e-3, mu, sigma, omega)
    while len(r_vals) < n_samples:
        r_try = np.random.uniform(Rc, Rc * 10, size=10000)
        u = np.random.uniform(0, max_pdf, size=10000)
        keep = u < mlp_pdf(r_try, mu, sigma, omega)
        r_vals.extend(r_try[keep])
    return np.array(r_vals[:n_samples])

def compute_conditional_expectations(mu, sigma, omega, Rc, H0, n_samples=100000):
    r_samples = sample_mlp_truncated(mu, sigma, omega, Rc, n_samples)
    mean_r = np.mean(r_samples)
    h_samples = H0 * (1 - Rc / r_samples)
    mean_h = np.mean(h_samples)
    return mean_r, mean_h

# Objective Function
def objective_ga(params):
    mu, sigma, omega, tau, Rc, H0, Ms = params
    if sigma <= 0 or omega <= 2 or tau <= 0 or Rc <= 0 or H0 <= 0 or Ms <= 0:
        return 1e6
    try:
        M_dyn = simulate_M_dynamic_conditional(H_empirical, mu, sigma, omega, Rc, H0, Ms, tau, t_grid)
        return np.sum((M_dyn - B_empirical)**2)
    except:
        return 1e6

# Parameter Bounds
# bounds = np.array([
#     [2.5, 3.0],    # mu
#     [0.1, 1.0],    # sigma
#     [2.1, 4.0],    # omega
#     [1e-3, 1.0],   # tau
#     [15.0, 50.0],  # Rc
#     [0.05, 3.0],   # H0
#     [25.0, 35.0]   # Ms
# ])

ga_config = {
    'max_num_iteration': 30,
    'population_size': 50,
    'mutation_probability': 0.1,
    'elit_ratio': 0.02,
    'crossover_probability': 0.5,
    'parents_portion': 0.3,
    'crossover_type': 'uniform',
    'max_iteration_without_improv': 10
}

model = GeneticAlgorithm(
    function=objective_ga,
    dimension=7,
    variable_type='real',
    variable_boundaries=bounds,
    algorithm_parameters=ga_config,
    convergence_curve=True,
    progress_bar=True
)

model.run()

mu_opt, sigma_opt, omega_opt, tau_opt, Rc_opt, H0_opt, Ms_opt = model.output_dict['variable']
M_fit = simulate_M_dynamic_conditional(H_empirical, mu_opt, sigma_opt, omega_opt, Rc_opt, H0_opt, Ms_opt, tau_opt, t_grid)

mean_r_num, mean_h_num = compute_conditional_expectations(mu_opt, sigma_opt, omega_opt, Rc_opt, H0_opt)

mean_r_num =expectation(mu_opt, sigma_opt, omega_opt)

print("Optimized Parameters:")
print(f"mu = {mu_opt:.4f}")
print(f"sigma = {sigma_opt:.4f}")
print(f"omega = {omega_opt:.4f}")
print(f"tau = {tau_opt:.4f}")
print(f"Rc = {Rc_opt:.4f} nm")
# print(f"H0 = {H0_opt:.4f} kOe")
# print(f"Ms = {Ms_opt:.4f} emu/g")
# print(f"Numerical mean R = {mean_r_num:.4f} nm")
# print(f"Numerical mean H = {mean_h_num:.4f} kOe")

plt.figure(figsize=(8, 6))
plt.plot(H_empirical, B_empirical, 'o', label='Empirical Hysteresis', color='black')
plt.plot(H_empirical, M_fit, '-', label='Theoretical Hysteresis', color='black')
plt.xlabel('$H$ (kOe)')
plt.ylabel('$M$ (emu/g)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
